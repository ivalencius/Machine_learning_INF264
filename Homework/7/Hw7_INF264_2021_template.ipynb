{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and plot the \"PCA.csv\" data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.genfromtxt('PCA.csv',delimiter=',')\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.scatter(X1[:, 0], X1[:, 1])\n",
    "    plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn's PCA to find 2 principal components on the X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# TODO \n",
    "# Fit a PCA with 2 components on the X (n_components=2)\n",
    "pca = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the explained variance of the eigenvectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the eigenvectors and the transformed datapoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "    # plot data\n",
    "    ax[0].scatter(X1[:, 0], X1[:, 1], alpha=0.2)\n",
    "    for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "        v = vector * 3 * np.sqrt(length)\n",
    "        draw_vector(pca.mean_, pca.mean_ + v, ax=ax[0])\n",
    "    ax[0].axis('equal');\n",
    "    ax[0].set(xlabel='x', ylabel='y', title='input')\n",
    "\n",
    "    # plot principal components\n",
    "    X_pca = pca.transform(X1)\n",
    "    ax[1].scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.2)\n",
    "    draw_vector([0, 0], [0, 3], ax=ax[1])\n",
    "    draw_vector([0, 0], [3, 0], ax=ax[1])\n",
    "    ax[1].axis('equal')\n",
    "    ax[1].set(xlabel='component 1', ylabel='component 2',\n",
    "              title='principal components',\n",
    "              xlim=(-5, 5), ylim=(-3, 3.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a sklearn PCA with only the first eigenvector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = ....\n",
    ".....\n",
    "X_pca = .....\n",
    "print(\"original shape:   \", X1.shape)\n",
    "print(\"transformed shape:\", X_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the X_pca back to 2 dimensions using pca.inverse_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# transform the X_pca back to two dimensions using pca.inverse_transform\n",
    "X_new = ....\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "    plt.scatter(X_new[:, 0], X_new[:, 1], alpha=0.8)\n",
    "    plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \n",
    "    header=None, \n",
    "    sep=',')\n",
    "\n",
    "df.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n",
    "df.dropna(how=\"all\", inplace=True) # drops the empty line at file-end\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract features and labels in X2 and y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Extract features and labels\n",
    "X2 = ...\n",
    "y2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def plot_histograms(X, y):\n",
    "  label_dict = {1: 'Iris-Setosa',\n",
    "                2: 'Iris-Versicolor',\n",
    "                3: 'Iris-Virgnica'}\n",
    "\n",
    "  feature_dict = {0: 'Sepal length [cm]',\n",
    "                  1: 'Sepal width [cm]',\n",
    "                  2: 'Petal length [cm]',\n",
    "                  3: 'Petal width [cm]'}\n",
    "\n",
    "  with plt.style.context('seaborn-whitegrid'):\n",
    "      plt.figure(figsize=(14, 6))\n",
    "      for cnt in range(4):\n",
    "          plt.subplot(2, 2, cnt+1)\n",
    "          for lab in ('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'):\n",
    "              plt.hist(X[y==lab, cnt],\n",
    "                       label=lab,\n",
    "                       bins=10,\n",
    "                       alpha=0.3,)\n",
    "          plt.xlabel(feature_dict[cnt])\n",
    "      plt.legend(loc='upper right', fancybox=True, fontsize=8)\n",
    "\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "\n",
    "plot_histograms(X2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the datapoints using StandardScaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# TODO\n",
    "# Standardize the data and assign them to X_std\n",
    "X_std = ...\n",
    "plot_histograms(X_std, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Complete the comput_cov using the formula given in the PDF file\n",
    "def comput_cov(X):\n",
    "    mean_vec = ...\n",
    "    cov_mat = ...\n",
    "    return cov_mat\n",
    "cov_mat = comput_cov(X_std)\n",
    "print(\"Covariance matrix: \\n%s\" %comput_cov(X_std) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_eigens(cov_mat):\n",
    "    eig_vals, eig_vecs = ...\n",
    "\n",
    "    print('Eigenvectors \\n%s' %eig_vecs)\n",
    "    print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "    # Make a list of (eigenvalue, eigenvector) tuples\n",
    "    eig_pairs = ...\n",
    "\n",
    "    # Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "    ...\n",
    "    return eig_pairs\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "eig_pairs = Sort_eigens(cov_mat)\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# compute the explained and cumulative explained variance\n",
    "\n",
    "var_exp = ...\n",
    "cum_var_exp = ...\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    plt.bar(range(4), var_exp, alpha=0.5, align='center',\n",
    "            label='individual explained variance')\n",
    "    plt.step(range(4), cum_var_exp, where='mid',\n",
    "             label='cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement MY_PCA() for full PCA procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def My_PCA(X,n_components):\n",
    "    cov_mat = ...\n",
    "    eig_pairs = ...\n",
    "    matrix_w = .... # initialize matrix_w\n",
    "    ..... # pick the first n eigen vectors from the sorted eig_pairs\n",
    "    print('Matrix W:\\n %s' %matrix_w)\n",
    "    Z = .... # reduce the dimensions of X and assign them to Z\n",
    "    return Z\n",
    "Z = My_PCA(X2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for lab, col in zip(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'), \n",
    "                        ('blue', 'red', 'green')):\n",
    "        plt.scatter(Z[y2==lab, 0],\n",
    "                    Z[y2==lab, 1],\n",
    "                    label=lab,\n",
    "                    c=col)\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend(loc='lower center')\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA from sklearn and see if the results match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# use sklearn pca on iris data\n",
    "sklearn_pca = ...\n",
    "Z_sklearn = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for lab, col in zip(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'), \n",
    "                        ('blue', 'red', 'green')):\n",
    "        plt.scatter(Z_sklearn[y2==lab, 0],\n",
    "                    Z_sklearn[y2==lab, 1],\n",
    "                    label=lab,\n",
    "                    c=col)\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend(loc='lower center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform your PCA on the X1 from the \"PCA.csv\" dataset with 1 dimension as well and compare it with X_pca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# perform PCA with 1 principal component on the X1 and compare it with X_pca\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders for dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the fashion mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(data, labels), (_, _) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(-1, 28*28) / 255. # scale the data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "#TODO\n",
    "# complete the function below for autoencoder\n",
    "def dim_red_ae(data,n_dims_encoded=2):\n",
    "    input_layer = layers.Input(shape=(...,))\n",
    "    encoding_layer = layers.Dense(.....,activation=...)(.....)\n",
    "    decoding_layer = layers.Dense(.....,activation=...) (......)\n",
    "    autoencoder = models.Model(....., .....)\n",
    "    autoencoder.compile('adam', loss='mse')\n",
    "    autoencoder.fit(x = ...., y = ...., epochs=...)\n",
    "    encoder = models.Model(......, .......)\n",
    "    return encoder,autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder,autoencoder = dim_red_ae(data,n_dims_encoded=2)\n",
    "encodings = encoder.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(encodings[:, 0], encodings[:, 1], c=labels)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = autoencoder.predict(data)\n",
    "img = img[0].reshape(28,28)\n",
    "plt.figure(figsize=(10, 10))\n",
    "fig,ax = plt.subplots(1,2)\n",
    "ax[0].imshow(data[0].reshape(28,28),cmap=\"Greys\")\n",
    "ax[1].imshow(img, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and run the autoencoder for 100 dimensions of the hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "encoder,autoencoder = ....\n",
    "img = autoencoder.predict(data)\n",
    "img = img[0].reshape(28,28)\n",
    "plt.figure(figsize=(10, 10))\n",
    "fig,ax = plt.subplots(1,2)\n",
    "ax[0].imshow(data[0].reshape(28,28),cmap=\"Greys\")\n",
    "ax[1].imshow(img, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train,X_test,y_train,y_test = train_test_split(data[:10000],labels[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# train and predict a KNN with K=3 on the training and test set and measure the time it takes.\n",
    "import time\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform cross validation to find the best number of hidden dimensions for hidden layer for dimensionality recudtion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# TODO\n",
    "# Perform K-fold cross validation with 5 folds to find the best number of hidden dimensions of autoencoder \n",
    "# for dimentionality reduction\n",
    "acc_list = []\n",
    "possible_dims = [2,5,7,10,15,20]\n",
    "for dims in possible_dims:\n",
    "    print(\"training for %d dimensions\"%dims)\n",
    "    ....\n",
    "    ....\n",
    "    ....\n",
    "    ....\n",
    "    print(\"for %d dims scores are :\"%dims,scores)\n",
    "    print(\"=========================================\")\n",
    "best_dim = ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform model evaluation with best_dim on the test set and measure the time of training and predicting of KNN (K=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# model evaluation on the test set.\n",
    "......\n",
    "\n",
    "......"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
