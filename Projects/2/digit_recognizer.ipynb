{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Digit Recognizer\r\n",
    "Ilan Valencius"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# QUESTIONS\r\n",
    "- Is number of layers a hyperparameter?\r\n",
    "- Should I evaluate the best of every model on the test set?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "import numpy as np\r\n",
    "import keras\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from math import log, exp\r\n",
    "import itertools\r\n",
    "import os\r\n",
    "from PIL import Image as im"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install Tensorflow GPU (CANT RUN IN INF264 venv)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.4/bin\")\r\n",
    "from tensorflow.keras.callbacks import EarlyStopping\r\n",
    "from tensorflow.keras import Sequential, layers\r\n",
    "from tensorflow.keras.losses import categorical_crossentropy\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\r\n",
    "import tensorflow as tf\r\n",
    "# print(tf.__version__)\r\n",
    "# print(tf.config.list_physical_devices())\r\n",
    "# sess = tf.Session()\r\n",
    "# To Check GPU usage\r\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\r\n",
    "\r\n",
    "\r\n",
    "# tf.test.is_gpu_available()\r\n",
    "# tf.test.is_built_with_cuda()\r\n",
    "# tf.compat.v1.disable_eager_execution()\r\n",
    "\r\n",
    "# hello = tf.constant('Hello, TensorFlow!')\r\n",
    "\r\n",
    "# sess = tf.compat.v1.Session()\r\n",
    "\r\n",
    "# print(sess.run(hello))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load CSV data\r\n",
    "x_data = np.genfromtxt('handwritten_digits_images.csv', delimiter=',')\r\n",
    "y_data = np.genfromtxt('handwritten_digits_labels.csv', delimiter=',')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Reshape images into 28 x 28 images\r\n",
    "# x_data = x_data.reshape(x_data.shape[0], 28, 28)\r\n",
    "\r\n",
    "# Plot image for quick sanity check\r\n",
    "plt.imshow(x_data.reshape(x_data.shape[0], 28, 28)[60000], cmap='Greys')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x263abd2fd30>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create train, validation, test sets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "seed = 120\r\n",
    "\r\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x_data,\r\n",
    "                                                            y_data,\r\n",
    "                                                            test_size=0.2,\r\n",
    "                                                            random_state=seed,\r\n",
    "                                                            shuffle=True)\r\n",
    "\r\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val,\r\n",
    "                                                  y_train_val,\r\n",
    "                                                  test_size=0.3,\r\n",
    "                                                  random_state=seed, \r\n",
    "                                                  shuffle=True)\r\n",
    "\r\n",
    "# Variables for model parameters\r\n",
    "y_classes = len(np.unique(y_data))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lists to store the best model from each type and its respective validation accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# To compare models\r\n",
    "model_type_accs = []\r\n",
    "model_type_best = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 1 - MLP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def construct_MLP(input_shape, num_layers=10, activation='relu'):\r\n",
    "    # Create model\r\n",
    "    MLP = Sequential()\r\n",
    "    MLP.add(layers.InputLayer(input_shape=input_shape))\r\n",
    "    # Intermediate Layers\r\n",
    "    for _ in range(1,num_layers):\r\n",
    "        MLP.add(layers.Dense(32, activation=activation))\r\n",
    "    # Output layer (fully-connected):\r\n",
    "    MLP.add(layers.Dense(y_classes, activation='softmax'))\r\n",
    "    # Compile Model\r\n",
    "    MLP.compile(optimizer='adam',\r\n",
    "                loss=categorical_crossentropy,\r\n",
    "                metrics=['accuracy'])\r\n",
    "    return MLP\r\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test MLP Model\r\n",
    "\r\n",
    "*Note* - With all parameters at 10 epochs can take around 5 minutes (using non GPU accelerated)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "y_train_one_hot = to_categorical(y_train)\r\n",
    "y_val_one_hot = to_categorical(y_val)\r\n",
    "\r\n",
    "# Set up hyperparameters to test\r\n",
    "num_layers = [1, 2, 5, 10]\r\n",
    "activation = ['relu', 'sigmoid', 'softmax', 'tanh']\r\n",
    "MLP_params = list(itertools.product(num_layers, activation))\r\n",
    "\r\n",
    "batch_sz = 64\r\n",
    "max_epochs = 10\r\n",
    "MLP_val_accs = []\r\n",
    "MLP_models = []\r\n",
    "# If you want Val_loss and Val_accuracy plots \r\n",
    "MLP_plotting = False\r\n",
    "# Iterate through and test every model\r\n",
    "for layer_num, act in MLP_params:\r\n",
    "    # print(tf.config.list_physical_devices())\r\n",
    "    MLP = construct_MLP(input_shape=784 ,num_layers=layer_num, activation=act)\r\n",
    "    # MLP_test.summary()\r\n",
    "    # Early callback stopping to avoid overfitting\r\n",
    "    callback = EarlyStopping(monitor='val_loss',\r\n",
    "                             patience=3,\r\n",
    "                             restore_best_weights=True)\r\n",
    "    \r\n",
    "    training_history = MLP.fit(x=x_train,y=y_train_one_hot,\r\n",
    "                                batch_size=batch_sz,\r\n",
    "                                epochs=max_epochs,\r\n",
    "                                validation_data=(x_val,y_val_one_hot),\r\n",
    "                                use_multiprocessing=True,\r\n",
    "                                verbose=0,\r\n",
    "                                callbacks=[callback])\r\n",
    "    MLP_models.append(MLP)\r\n",
    "    \r\n",
    "    val_acc = training_history.history['val_accuracy']\r\n",
    "    MLP_val_accs.append(max(val_acc))\r\n",
    "    if MLP_plotting:\r\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\r\n",
    "        fig.suptitle('MLP Model - %d layers | %s activation'%(layer_num, act))\r\n",
    "        \r\n",
    "        loss = training_history.history['loss']\r\n",
    "        val_loss = training_history.history['val_loss']\r\n",
    "        acc = training_history.history['accuracy']\r\n",
    "        \r\n",
    "        epochs = range(1, len(loss) + 1)\r\n",
    "        ax1.plot(epochs, loss, 'y', label='Training loss')\r\n",
    "        ax1.plot(epochs, val_loss, 'r', label='Validation loss')\r\n",
    "        ax1.title.set_text('Training and validation loss')\r\n",
    "        ax1.set_xlabel('Epochs')\r\n",
    "        ax1.set_ylabel('Loss')\r\n",
    "        ax1.legend(loc='best')\r\n",
    "        \r\n",
    "        ax2.plot(epochs, acc, 'y', label='Training Accuracy')\r\n",
    "        ax2.plot(epochs, val_acc, 'r', label='Validation Accuracy')\r\n",
    "        ax2.title.set_text('Training and validation Accuracy')\r\n",
    "        ax2.set_xlabel('Epochs')\r\n",
    "        ax2.set_ylabel('Accuracy')\r\n",
    "        ax2.legend(loc='best')\r\n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Determine best MLP model (using validation set)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Evaluate best model via validation accuracy\r\n",
    "best_MLP_idx = MLP_val_accs.index(max(MLP_val_accs))\r\n",
    "best_MLP = MLP_models[best_MLP_idx]\r\n",
    "model_type_best.append(best_MLP)\r\n",
    "best_MLP.summary()\r\n",
    "\r\n",
    "activation = best_MLP.layers[1].get_config()['activation']\r\n",
    "num_layers = len(best_MLP.layers)\r\n",
    "\r\n",
    "print('\\n\\tActivation: %s\\n\\tNumber of Layers: %d'%(activation, num_layers))\r\n",
    "\r\n",
    "# Evaluate on validation accuracy again and plot \r\n",
    "MLP_eval = best_MLP.evaluate(x=x_val, y=y_val_one_hot, use_multiprocessing=True, verbose=0)\r\n",
    "MLP_loss = MLP_eval[0]\r\n",
    "MLP_acc = MLP_eval[1]\r\n",
    "\r\n",
    "model_type_accs.append(MLP_acc)\r\n",
    "\r\n",
    "print('\\nTest Set evaluation:')\r\n",
    "print('\\tLoss: %f | Accuracy: %f'%(MLP_loss, MLP_acc))\r\n",
    "# Plot training history (train/validation loss and accuracy values throughout training):\r\n",
    "loss = training_history.history['loss']\r\n",
    "val_loss = training_history.history['val_loss']\r\n",
    "epochs = range(1, len(loss) + 1)\r\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\r\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\r\n",
    "plt.title('Training and validation loss')\r\n",
    "plt.xlabel('Epochs')\r\n",
    "plt.ylabel('Loss')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "acc = training_history.history['accuracy']\r\n",
    "val_acc = training_history.history['val_accuracy']\r\n",
    "\r\n",
    "plt.plot(epochs, acc, 'y', label='Training Accuracy')\r\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\r\n",
    "plt.title('Training and validation Accuracy')\r\n",
    "plt.xlabel('Epochs')\r\n",
    "plt.ylabel('Accuracy')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'MLP_val_accs' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10740/3627478633.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Evaluate best model via validation accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest_MLP_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP_val_accs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLP_val_accs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbest_MLP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_MLP_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_type_best\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_MLP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbest_MLP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MLP_val_accs' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model 2 - CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def construct_CNN(input_shape, additional_layer=False, activation='relu'):\r\n",
    "    # Create model\r\n",
    "    CNN = Sequential()\r\n",
    "    # Intermediate Layers\r\n",
    "    CNN.add(layers.Conv2D(28, (3, 3), activation=activation, input_shape=input_shape))\r\n",
    "    CNN.add(layers.MaxPooling2D((2, 2)))\r\n",
    "    CNN.add(layers.Conv2D(56, (3, 3), activation=activation))\r\n",
    "    if additional_layer:\r\n",
    "        CNN.add(layers.MaxPooling2D((2, 2)))\r\n",
    "        CNN.add(layers.Conv2D(56, (3, 3), activation=activation))\r\n",
    "    # Output layer (fully-connected):\r\n",
    "    CNN.add(layers.Flatten())\r\n",
    "    CNN.add(layers.Dense(y_classes, activation='softmax'))\r\n",
    "    # Compile Model\r\n",
    "    CNN.compile(optimizer='adam',\r\n",
    "                loss=categorical_crossentropy,\r\n",
    "                metrics=['accuracy'])\r\n",
    "    return CNN"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test CNN Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set up hyperparameters to test\r\n",
    "add_layers = [False, True]\r\n",
    "activation = ['relu', 'sigmoid', 'softmax', 'tanh']\r\n",
    "CNN_params = list(itertools.product(add_layers, activation))\r\n",
    "\r\n",
    "CNN_val_accs = []\r\n",
    "CNN_models = []\r\n",
    "# If you want Val_loss and Val_accuracy plots \r\n",
    "CNN_plotting = False\r\n",
    "\r\n",
    "# Reshape x_train into (28, 28) imgs\r\n",
    "x_train_img = x_train.reshape(x_train.shape[0], 28, 28, 1)\r\n",
    "x_val_img = x_val.reshape(x_val.shape[0], 28, 28, 1)\r\n",
    "\r\n",
    "\r\n",
    "# Iterate through and test every model\r\n",
    "for add_layer, act in CNN_params:\r\n",
    "    CNN = construct_CNN(input_shape=(28, 28, 1) ,additional_layer=add_layer, activation=act)\r\n",
    "    CNN.summary()\r\n",
    "    # Early callback stopping to avoid overfitting\r\n",
    "    callback = EarlyStopping(monitor='val_loss',\r\n",
    "                             patience=3,\r\n",
    "                             restore_best_weights=True)\r\n",
    "    \r\n",
    "    training_history = CNN.fit(x=x_train_img,y=y_train_one_hot,\r\n",
    "                                batch_size=batch_sz,\r\n",
    "                                epochs=max_epochs,\r\n",
    "                                validation_data=(x_val_img,y_val_one_hot),\r\n",
    "                                use_multiprocessing=True,\r\n",
    "                                verbose=1,\r\n",
    "                                callbacks=[callback])\r\n",
    "    CNN_models.append(MLP)\r\n",
    "    \r\n",
    "    val_acc = training_history.history['val_accuracy']\r\n",
    "    CNN_val_accs.append(max(val_acc))\r\n",
    "    if CNN_plotting:\r\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\r\n",
    "        fig.suptitle('CNN Model - %d additional layers | %s activation'%(layer_num, act))\r\n",
    "        \r\n",
    "        loss = training_history.history['loss']\r\n",
    "        val_loss = training_history.history['val_loss']\r\n",
    "        acc = training_history.history['accuracy']\r\n",
    "        \r\n",
    "        epochs = range(1, len(loss) + 1)\r\n",
    "        ax1.plot(epochs, loss, 'y', label='Training loss')\r\n",
    "        ax1.plot(epochs, val_loss, 'r', label='Validation loss')\r\n",
    "        ax1.title.set_text('Training and validation loss')\r\n",
    "        ax1.set_xlabel('Epochs')\r\n",
    "        ax1.set_ylabel('Loss')\r\n",
    "        ax1.legend(loc='best')\r\n",
    "        \r\n",
    "        ax2.plot(epochs, acc, 'y', label='Training Accuracy')\r\n",
    "        ax2.plot(epochs, val_acc, 'r', label='Validation Accuracy')\r\n",
    "        ax2.title.set_text('Training and validation Accuracy')\r\n",
    "        ax2.set_xlabel('Epochs')\r\n",
    "        ax2.set_ylabel('Accuracy')\r\n",
    "        ax2.legend(loc='best')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 13, 13, 28)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 11, 11, 56)        14168     \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 6776)              0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 10)                67770     \n",
      "=================================================================\n",
      "Total params: 82,218\n",
      "Trainable params: 82,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 17s 26ms/step - loss: 0.6291 - accuracy: 0.9304 - val_loss: 0.0882 - val_accuracy: 0.9730\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 14s 23ms/step - loss: 0.0721 - accuracy: 0.9785 - val_loss: 0.0807 - val_accuracy: 0.9752\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 14s 23ms/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 0.0830 - val_accuracy: 0.9776\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 16s 26ms/step - loss: 0.0392 - accuracy: 0.9881 - val_loss: 0.0951 - val_accuracy: 0.9751\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 15s 25ms/step - loss: 0.0380 - accuracy: 0.9876 - val_loss: 0.0882 - val_accuracy: 0.9790\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 13, 13, 28)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 11, 11, 56)        14168     \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 6776)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 10)                67770     \n",
      "=================================================================\n",
      "Total params: 82,218\n",
      "Trainable params: 82,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 20s 31ms/step - loss: 0.5955 - accuracy: 0.8272 - val_loss: 0.1962 - val_accuracy: 0.9434\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 17s 28ms/step - loss: 0.1346 - accuracy: 0.9610 - val_loss: 0.0923 - val_accuracy: 0.9733\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 18s 29ms/step - loss: 0.0848 - accuracy: 0.9745 - val_loss: 0.0741 - val_accuracy: 0.9761\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 16s 27ms/step - loss: 0.0658 - accuracy: 0.9803 - val_loss: 0.0646 - val_accuracy: 0.9805\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 16s 26ms/step - loss: 0.0553 - accuracy: 0.9828 - val_loss: 0.0606 - val_accuracy: 0.9814\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 16s 27ms/step - loss: 0.0456 - accuracy: 0.9864 - val_loss: 0.0577 - val_accuracy: 0.9813\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 17s 28ms/step - loss: 0.0397 - accuracy: 0.9876 - val_loss: 0.0550 - val_accuracy: 0.9830\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 18s 30ms/step - loss: 0.0353 - accuracy: 0.9892 - val_loss: 0.0478 - val_accuracy: 0.9849\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 17s 28ms/step - loss: 0.0299 - accuracy: 0.9901 - val_loss: 0.0536 - val_accuracy: 0.9836\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 20s 33ms/step - loss: 0.0249 - accuracy: 0.9925 - val_loss: 0.0487 - val_accuracy: 0.9845\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_56 (Conv2D)           (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 13, 13, 28)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 11, 11, 56)        14168     \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 6776)              0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 10)                67770     \n",
      "=================================================================\n",
      "Total params: 82,218\n",
      "Trainable params: 82,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 28s 44ms/step - loss: 0.5268 - accuracy: 0.8624 - val_loss: 0.1098 - val_accuracy: 0.9688\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 22s 36ms/step - loss: 0.0872 - accuracy: 0.9759 - val_loss: 0.0703 - val_accuracy: 0.9802\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 23s 38ms/step - loss: 0.0611 - accuracy: 0.9831 - val_loss: 0.0628 - val_accuracy: 0.9816\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 24s 39ms/step - loss: 0.0494 - accuracy: 0.9858 - val_loss: 0.0546 - val_accuracy: 0.9843\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 25s 41ms/step - loss: 0.0405 - accuracy: 0.9891 - val_loss: 0.0460 - val_accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 25s 41ms/step - loss: 0.0339 - accuracy: 0.9907 - val_loss: 0.0442 - val_accuracy: 0.9867\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 29s 47ms/step - loss: 0.0291 - accuracy: 0.9921 - val_loss: 0.0412 - val_accuracy: 0.9870\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 26s 42ms/step - loss: 0.0248 - accuracy: 0.9939 - val_loss: 0.0394 - val_accuracy: 0.9876\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 27s 44ms/step - loss: 0.0223 - accuracy: 0.9943 - val_loss: 0.0395 - val_accuracy: 0.9876\n",
      "Epoch 10/10\n",
      "241/613 [==========>...................] - ETA: 14s - loss: 0.0204 - accuracy: 0.9951"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19952/1180479153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m                              restore_best_weights=True)\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     training_history = CNN.fit(x=x_train_img,y=y_train_one_hot,\n\u001b[0m\u001b[0;32m     26\u001b[0m                                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "f8dc394fe8b851e8fee8bf44b9060daf20dc28cf237837a1e07d4467514055a5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}